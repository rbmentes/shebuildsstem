<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>LID Project | SheBuildsSTEM</title>
  <link rel="icon" href="favicon.jpg">
  <link rel="stylesheet" href="style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<header>
  <!-- Language Switch -->
  <div class="lang">
    <a href="project-lid.html" class="active">ğŸ‡¬ğŸ‡§ EN</a>
    <a href="project-lid-tr.html">ğŸ‡¹ğŸ‡· TR</a>
  </div>
</header>

<section>
  <div class="card project-card">

    <h1>ğŸ¤ Language Identification (LID) Project</h1>

    <p>
      This project was developed as part of my
      <b>Introduction to Speech Processing</b> course.
      The main goal was to build a system that can automatically
      recognize the spoken language from short audio recordings.
    </p>

    <hr>

    <h2>ğŸ“‚ Dataset</h2>
    <p>
      I used an open-source dataset available on Kaggle.
      The dataset contains short speech samples from multiple languages.
      Working with real audio data helped me better understand how speech
      processing systems are trained and evaluated.
    </p>

    <hr>

    <h2>âœ¨ Methods Implemented</h2>

    <h3>1ï¸âƒ£ MFCC (Mel-Frequency Cepstral Coefficients)</h3>
    <p>
      I started the project with a more classical approach using MFCC features.
      This was the first stage where I was learning how language identification works.
      The code was easier to build, but the results were not very strong,
      since MFCC-based methods are more traditional and limited compared to deep learning.
    </p>

    <h3>2ï¸âƒ£ CNN (Convolutional Neural Network)</h3>
    <p>
      After that, I moved to a more modern approach using a CNN model.
      This method produced better performance and improved accuracy.
    </p>

    <p>
      The most challenging part of this stage was trying to increase the modelâ€™s accuracy.
      I had to carefully analyze what was causing errors in training and prediction,
      then adjust parameters and improve the model step by step.
    </p>

    <hr>

    <h2>ğŸ“Š Results</h2>

    <p><b>Validation Accuracy:</b> 64.61%</p>

    <p>
      The CNN model was trained for 10 epochs, and the best model was saved during training.
      Overall, CNN achieved better results compared to the MFCC baseline method.
    </p>

    <hr>

    <h2>ğŸ’» Tools & Technologies</h2>

    <ul>
      <li>Python</li>
      <li>Google Colab</li>
      <li>Kaggle Dataset</li>
      <li>Audio Feature Extraction (MFCC)</li>
      <li>Deep Learning (CNN)</li>
    </ul>

    <hr>

    <h2>ğŸŒ· What This Project Taught Me</h2>

    <p>
      This project helped me understand how speech-processing projects are developed in Python.
      I learned how to use Google Colab efficiently, work with audio data,
      and explore the exciting field of language identification.
    </p>

    <p>
      Most importantly, I realized that improving model performance requires patience,
      experimentation, and a lot of problem-solving â€” and thatâ€™s what made the project so rewarding.
    </p>

    <hr>

    <h2>ğŸ”— GitHub Repository</h2>

    <p>
      You can explore the full code and notebooks here:
    </p>

    <a href="https://github.com/rbmentes/lid-language-identification"
       target="_blank"
       class="btn">
       View on GitHub â†’
    </a>

  </div>
</section>

</body>
</html>

